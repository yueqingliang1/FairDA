{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exp1_optim1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from fairlearn.metrics import MetricFrame\n",
    "import argparse\n",
    "\n",
    "seed = 9 # 需要调\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 320\n",
    "random_state = seed\n",
    "# shuffle_dataset = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- data ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_attr = 'sex'\n",
    "predict_attr = \"is_recid\"\n",
    "\n",
    "# ------------- source -------------\n",
    "\n",
    "data_name='Processed_Compas'\n",
    "compas = pd.read_csv(\"../data/{}.csv\".format(data_name))\n",
    "\n",
    "header = list(compas.columns)\n",
    "compas.dropna(inplace=True)\n",
    "compas = compas[compas.race.isin(['African-American', 'Caucasian'])]\n",
    "compas = compas[compas['age']<24]\n",
    "\n",
    "sensitive_attr_src = compas[sens_attr]\n",
    "A1_true = pd.get_dummies(sensitive_attr_src)\n",
    "A1_true = A1_true.drop(['Male'], axis=1)\n",
    "A1_true = A1_true['Female'].values\n",
    "\n",
    "header.remove('age_cat')\n",
    "header.remove(sens_attr)\n",
    "header.remove(predict_attr)\n",
    "\n",
    "X_src = pd.get_dummies(compas[header])\n",
    "X_src = X_src.sort_index(axis=1)\n",
    "y_true_src = compas[predict_attr].values\n",
    "\n",
    "\n",
    "# ------------- target -------------\n",
    "\n",
    "\n",
    "data_name='Processed_Compas'\n",
    "compas = pd.read_csv(\"../data/{}.csv\".format(data_name))\n",
    "\n",
    "header = list(compas.columns)\n",
    "compas.dropna(inplace=True)\n",
    "compas = compas[compas.race.isin(['African-American', 'Caucasian'])]\n",
    "compas = compas[compas['age']>=24]\n",
    "\n",
    "sensitive_attr_tgt = compas[sens_attr]\n",
    "\n",
    "header.remove(predict_attr)\n",
    "header.remove(sens_attr)\n",
    "\n",
    "X_tgt = pd.get_dummies(compas[header])\n",
    "X_tgt = X_tgt.sort_index(axis=1)\n",
    "y_true_tgt = compas[predict_attr].values\n",
    "\n",
    "n_classes = y_true_tgt.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- preprocess ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# source training samples: 528\n",
      "# source batches: 1\n",
      "# target training samples: 2198\n",
      "# target batches: 6\n"
     ]
    }
   ],
   "source": [
    "class PandasDataSet(TensorDataset):\n",
    "\n",
    "    def __init__(self, *dataframes):\n",
    "        tensors = (self._df_to_tensor(df) for df in dataframes)\n",
    "        super(PandasDataSet, self).__init__(*tensors)\n",
    "\n",
    "    def _df_to_tensor(self, df):\n",
    "        if isinstance(df, np.ndarray):\n",
    "            return torch.from_numpy(df).float()\n",
    "        return torch.from_numpy(df.values).float()\n",
    "\n",
    "# ------------- source -------------\n",
    "# if domain=='source': train/test = 0.6:0.4\n",
    "train_ratio = 0.6\n",
    "test_ratio = 0.4\n",
    "\n",
    "indict_src = np.arange(sensitive_attr_src.shape[0])\n",
    "(X_train_src, X_test_src, y_train_src, y_test_src, A1_train, A1_test, ind_train_src, ind_test_src) = train_test_split(X_src, y_true_src, A1_true, indict_src, test_size=test_ratio, stratify=y_true_src, random_state=random_state)\n",
    "\n",
    "# processed_X_train_src = X_train_src\n",
    "\n",
    "# standardize the data\n",
    "scaler_src = StandardScaler().fit(X_train_src)\n",
    "X_train_src = scaler_src.transform(X_train_src)\n",
    "X_test_src = scaler_src.transform(X_test_src)\n",
    "\n",
    "train_data_src = PandasDataSet(X_train_src, y_train_src, A1_train, ind_train_src)\n",
    "test_data_src = PandasDataSet(X_test_src, y_test_src, A1_test, ind_test_src)\n",
    "\n",
    "src_train_loader = DataLoader(train_data_src, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print('# source training samples:', len(train_data_src))\n",
    "print('# source batches:', len(src_train_loader))\n",
    "\n",
    "# ------------- target -------------\n",
    "# else: domain=='target': train/valid/test set = 0.5:0.25:0.25\n",
    "train_ratio = 0.5\n",
    "test_ratio = 0.25\n",
    "valid_ratio = 0.25\n",
    "\n",
    "# split into train/test set\n",
    "indict_tgt = np.arange(sensitive_attr_tgt.shape[0])\n",
    "(X_train_tgt, X_test_tgt, y_train_tgt, y_test_tgt, ind_train_tgt, ind_test_tgt) = train_test_split(X_tgt, y_true_tgt, indict_tgt, test_size=test_ratio, stratify=y_true_tgt, random_state=random_state)\n",
    "\n",
    "# split training set into train/validation set\n",
    "(X_train_tgt, X_valid_tgt, y_train_tgt, y_valid_tgt, ind_train_tgt, ind_valid_tgt) = train_test_split(X_train_tgt, y_train_tgt, ind_train_tgt, test_size=valid_ratio/(train_ratio+valid_ratio), stratify=y_train_tgt, random_state=random_state)\n",
    "\n",
    "# processed_X_train_tgt = X_train_tgt\n",
    "\n",
    "# standardize the data\n",
    "scaler_tgt = StandardScaler().fit(X_train_tgt)\n",
    "X_train_tgt = scaler_tgt.transform(X_train_tgt)\n",
    "X_valid_tgt = scaler_tgt.transform(X_valid_tgt)\n",
    "X_test_tgt = scaler_tgt.transform(X_test_tgt)\n",
    "\n",
    "train_data_tgt = PandasDataSet(X_train_tgt, y_train_tgt, ind_train_tgt)\n",
    "test_data_tgt = PandasDataSet(X_test_tgt, y_test_tgt, ind_test_tgt)\n",
    "valid_data_tgt = PandasDataSet(X_valid_tgt, y_valid_tgt, ind_valid_tgt)\n",
    "\n",
    "tgt_train_loader = DataLoader(train_data_tgt, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print('# target training samples:', len(train_data_tgt))\n",
    "print('# target batches:', len(tgt_train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper(nn.Module):\n",
    "    \"\"\"\n",
    "        Mapping feature dimensions of src and tgt domain into the same.\n",
    "    \"\"\"\n",
    "    def __init__(self, ori_dims, n_features=16):\n",
    "        super().__init__()\n",
    "        self.map = nn.Sequential(\n",
    "            nn.Linear(ori_dims, n_features),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = self.map(x).squeeze()\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "        Hidden Embedding Layer h\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features=16, n_hidden=32, p_dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden*2, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "#             nn.Linear(n_hidden, n_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, m):\n",
    "        emb = self.emb(m)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "        Classification head\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=32, n_class=2):\n",
    "        super().__init__()\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_class),\n",
    "        )\n",
    "    def forward(self, emb):\n",
    "        cls = self.cls(emb)\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg()\n",
    "\n",
    "        return output, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "        Discrimination head\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=32, n_adv=2):\n",
    "        super().__init__()\n",
    "        self.adv = nn.Sequential(\n",
    "            nn.Linear(n_hidden, n_adv),\n",
    "        )\n",
    "    def forward(self, emb):\n",
    "        reversed_input = ReverseLayerF.apply(emb)\n",
    "        adv = self.adv(reversed_input)\n",
    "        return adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_dims_src = X_src.shape[1]\n",
    "ori_dims_tgt = X_tgt.shape[1]\n",
    "lr = 0.0001 # 需要调\n",
    "\n",
    "# n_features = X.shape[1]\n",
    "\n",
    "M1 = Mapper(ori_dims=ori_dims_src).to(DEVICE)\n",
    "M2 = Mapper(ori_dims=ori_dims_tgt).to(DEVICE)\n",
    "H1 = Encoder().to(DEVICE)\n",
    "H2 = Encoder().to(DEVICE)\n",
    "FA = Classifier().to(DEVICE)\n",
    "L2 = Classifier().to(DEVICE)\n",
    "D1 = Discriminator().to(DEVICE)\n",
    "D2 = Discriminator().to(DEVICE)\n",
    "\n",
    "L_params = list(M1.parameters()) + list(M2.parameters()) + list(H1.parameters()) + list(FA.parameters()) + list(D1.parameters())\n",
    "R_params = list(H2.parameters()) + list(L2.parameters()) + list(D2.parameters())\n",
    "\n",
    "L_optim = optim.Adam(L_params, lr = lr)\n",
    "R_optim = optim.Adam(R_params, lr = lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FairDA_transfer_train(M1, M2, H1, FA, D1, src_train_loader, L_optim, criterion):\n",
    "\n",
    "    for batch_idx, (src, tgt) in enumerate(zip(src_train_loader, tgt_train_loader)):\n",
    "        X1_train, _, A1_train, _ = src\n",
    "        X2_train, _, _ = tgt\n",
    "        \n",
    "        X1 = X1_train.to(torch.float32).to(DEVICE)\n",
    "        X2 = X2_train.to(torch.float32).to(DEVICE)\n",
    "        A1 = A1_train.to(torch.float32).to(DEVICE)\n",
    "        \n",
    "        L_optim.zero_grad()\n",
    "        \n",
    "        m1 = M1(X1)\n",
    "        m2 = M2(X2)\n",
    "        m12 = torch.cat([m1, m2], dim=0)\n",
    "        h1 = H1(m12)\n",
    "        \n",
    "        \n",
    "        # ---------------------------\n",
    "        #   Train: FA, H1, M1, M2\n",
    "        # ---------------------------\n",
    "        A1_hat = FA(h1[:batch_size])\n",
    "        loss_FA = criterion(A1_hat, A1.long())\n",
    "        \n",
    "        # --------------\n",
    "        #    Train D1\n",
    "        # --------------\n",
    "        D1_hat = D1(h1)\n",
    "        \n",
    "        D_src = torch.zeros(X1.shape[0]).to(DEVICE)\n",
    "        D_tgt = torch.ones(X2.shape[0]).to(DEVICE)\n",
    "        D_labels = torch.cat([D_src, D_tgt], dim=0).long()\n",
    "        \n",
    "        loss_D1 = criterion(D1_hat, D_labels)\n",
    "        \n",
    "        # -------------------\n",
    "        #    Transfer loss\n",
    "        # -------------------\n",
    "        loss_left = loss_FA + loss_D1\n",
    "        loss_left.backward()\n",
    "        \n",
    "        L_optim.step()\n",
    "        \n",
    "\n",
    "    return M1, M2, H1, FA, D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FairDA_debias_train(H2, L2, D2, FA, H1, M2, tgt_train_loader, R_optim, criterion, D2_weights):\n",
    "    for batch_idx, (X2_train, Y2_train, _) in enumerate(tgt_train_loader):\n",
    "        \n",
    "        X2 = X2_train.to(torch.float32).to(DEVICE)\n",
    "        Y2 = Y2_train.to(torch.float32).to(DEVICE)\n",
    "        \n",
    "        R_optim.zero_grad()\n",
    "\n",
    "        h2 = H2(M2(X2))\n",
    "\n",
    "        # ---------------------------\n",
    "        #   Train: H2, L2\n",
    "        # ---------------------------\n",
    "        Y2_hat = L2(h2)\n",
    "        loss_L2 = criterion(Y2_hat, Y2.long())\n",
    "\n",
    "        # --------------\n",
    "        #    Train D2\n",
    "        # --------------\n",
    "        A2_hat = D2(h2)\n",
    "        A2_ground = FA(H1(M2(X2))).detach()\n",
    "        A2_ground = A2_ground.argmax(dim=1)\n",
    "        loss_D2 = criterion(A2_hat, A2_ground)\n",
    "        \n",
    "        # --------------------\n",
    "        #    Debiasing loss\n",
    "        # --------------------\n",
    "        loss_right = loss_L2 + D2_weights * loss_D2\n",
    "        loss_right.backward()\n",
    "\n",
    "        R_optim.step()\n",
    "        \n",
    "        \n",
    "    return H2, L2, D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_metric(sens_ind, y2_pred, y2_true):\n",
    "\n",
    "    group_dp = []\n",
    "    group_equal_odds = []\n",
    "    sens_data = sensitive_attr_tgt.iloc[sens_ind]\n",
    "\n",
    "\n",
    "    for sens_value in set(sens_data):\n",
    "        y_sense_pred = y2_pred[(sens_data==sens_value).values]\n",
    "        y_sense_test = y2_true[(sens_data==sens_value).values]\n",
    "        sens_dp = []\n",
    "        sens_eo = []\n",
    "\n",
    "        for label in set(y2_true):\n",
    "            if label>0:\n",
    "                sens_dp_label = (y_sense_pred==label).sum()/y_sense_pred.shape[0]\n",
    "                sens_eo_label = (y_sense_pred[y_sense_test==label]==label).sum()/(y_sense_test==label).sum()\n",
    "\n",
    "                sens_dp.append(sens_dp_label)\n",
    "                sens_eo.append(sens_eo_label)\n",
    "\n",
    "        group_dp.append(sens_dp)\n",
    "        group_equal_odds.append(sens_eo)\n",
    "\n",
    "    group_dp = np.array(group_dp)\n",
    "    group_eo = np.array(group_equal_odds)\n",
    "\n",
    "    dp_diff = np.mean(np.absolute(group_dp-np.mean(group_dp, axis=0, keepdims=True)))\n",
    "    eo_diff = np.mean(np.absolute(group_equal_odds-np.mean(group_equal_odds, axis=0, keepdims=True)))\n",
    "\n",
    "    return group_dp, group_eo, dp_diff, eo_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "                 Pretraining on source finished                   \n",
      "                       Best epoch: 0135                         \n",
      "                 Best ACC on pretraining: 0.8215                  \n",
      "==================================================================\n",
      "************ Test result: accuracy_Y2: 0.5227, F1_Y2: 0.0038       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5227, F1_Y2: 0.0038       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5245, F1_Y2: 0.0113       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5264, F1_Y2: 0.0188       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5273, F1_Y2: 0.0226       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5273, F1_Y2: 0.0226       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5273, F1_Y2: 0.0226       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5282, F1_Y2: 0.0263       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5282, F1_Y2: 0.0263       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5282, F1_Y2: 0.0263       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5400, F1_Y2: 0.0833       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5618, F1_Y2: 0.1718       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5700, F1_Y2: 0.2156       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5818, F1_Y2: 0.2698       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5936, F1_Y2: 0.3112       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6018, F1_Y2: 0.3384       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5964, F1_Y2: 0.3471       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5945, F1_Y2: 0.3573       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.5991, F1_Y2: 0.3762       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6027, F1_Y2: 0.3939       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6127, F1_Y2: 0.4228       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6173, F1_Y2: 0.4334       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6227, F1_Y2: 0.4503       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.23295455]\n",
      " [0.10909091]]\n",
      "Group EO:\n",
      "[[0.34615386]\n",
      " [0.20238096]]\n",
      "************ Test result: accuracy_Y2: 0.6291, F1_Y2: 0.4687       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6309, F1_Y2: 0.4781       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6382, F1_Y2: 0.4975       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.2693182 ]\n",
      " [0.13181818]]\n",
      "Group EO:\n",
      "[[0.39819005]\n",
      " [0.25      ]]\n",
      "************ Test result: accuracy_Y2: 0.6436, F1_Y2: 0.5124       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6473, F1_Y2: 0.5222       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6518, F1_Y2: 0.5324       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6536, F1_Y2: 0.5382       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6555, F1_Y2: 0.5450       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6591, F1_Y2: 0.5552       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6627, F1_Y2: 0.5651       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6655, F1_Y2: 0.5721       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6664, F1_Y2: 0.5757       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6673, F1_Y2: 0.5803       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.3465909 ]\n",
      " [0.18636364]]\n",
      "Group EO:\n",
      "[[0.5045249 ]\n",
      " [0.35714287]]\n",
      "************ Test result: accuracy_Y2: 0.6691, F1_Y2: 0.5854       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.35227272]\n",
      " [0.19090909]]\n",
      "Group EO:\n",
      "[[0.51357466]\n",
      " [0.35714287]]\n",
      "************ Test result: accuracy_Y2: 0.6691, F1_Y2: 0.5854       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6718, F1_Y2: 0.5902       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.35454544]\n",
      " [0.19545455]]\n",
      "Group EO:\n",
      "[[0.51809955]\n",
      " [0.3690476 ]]\n",
      "************ Test result: accuracy_Y2: 0.6736, F1_Y2: 0.5953       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.3590909 ]\n",
      " [0.20454545]]\n",
      "Group EO:\n",
      "[[0.5248869]\n",
      " [0.3809524]]\n",
      "************ Test result: accuracy_Y2: 0.6727, F1_Y2: 0.5937       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6745, F1_Y2: 0.5968       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6764, F1_Y2: 0.6000       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6764, F1_Y2: 0.6018       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6773, F1_Y2: 0.6051       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6075       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.375    ]\n",
      " [0.2090909]]\n",
      "Group EO:\n",
      "[[0.54751134]\n",
      " [0.3809524 ]]\n",
      "************ Test result: accuracy_Y2: 0.6764, F1_Y2: 0.6079       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6118       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6764, F1_Y2: 0.6088       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6773, F1_Y2: 0.6103       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6134       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.38295454]\n",
      " [0.22727273]]\n",
      "Group EO:\n",
      "[[0.5565611]\n",
      " [0.4047619]]\n",
      "************ Test result: accuracy_Y2: 0.6809, F1_Y2: 0.6164       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6809, F1_Y2: 0.6164       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6159       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6818, F1_Y2: 0.6196       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6827, F1_Y2: 0.6211       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6818, F1_Y2: 0.6204       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.3897727 ]\n",
      " [0.24090908]]\n",
      "Group EO:\n",
      "[[0.5656109 ]\n",
      " [0.42857143]]\n",
      "************ Test result: accuracy_Y2: 0.6818, F1_Y2: 0.6196       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.3875    ]\n",
      " [0.24090908]]\n",
      "Group EO:\n",
      "[[0.5633484 ]\n",
      " [0.42857143]]\n",
      "************ Test result: accuracy_Y2: 0.6809, F1_Y2: 0.6189       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6800, F1_Y2: 0.6190       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6161       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6161       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6773, F1_Y2: 0.6154       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.3897727 ]\n",
      " [0.24545455]]\n",
      "Group EO:\n",
      "[[0.5588235 ]\n",
      " [0.44047618]]\n",
      "************ Test result: accuracy_Y2: 0.6773, F1_Y2: 0.6154       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6773, F1_Y2: 0.6154       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6161       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6773, F1_Y2: 0.6145       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.38863635]\n",
      " [0.24090908]]\n",
      "Group EO:\n",
      "[[0.5588235 ]\n",
      " [0.42857143]]\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6184       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6809, F1_Y2: 0.6214       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6818, F1_Y2: 0.6228       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6200       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6200       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6800, F1_Y2: 0.6207       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6800, F1_Y2: 0.6215       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6200       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6194       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6200       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6200       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6194       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6217       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6773, F1_Y2: 0.6211       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6226       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6234       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6234       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6249       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6242       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6249       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6249       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6773, F1_Y2: 0.6227       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6241       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6234       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6249       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6242       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6242       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6265       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6272       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6280       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6800, F1_Y2: 0.6287       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6280       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6800, F1_Y2: 0.6295       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6809, F1_Y2: 0.6294       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6800, F1_Y2: 0.6279       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6800, F1_Y2: 0.6279       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6809, F1_Y2: 0.6294       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6818, F1_Y2: 0.6308       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6818, F1_Y2: 0.6308       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6250       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6782, F1_Y2: 0.6250       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6791, F1_Y2: 0.6265       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6800, F1_Y2: 0.6271       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6827, F1_Y2: 0.6307       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6336       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6336       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6328       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6342       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6342       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6357       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6357       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6357       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6873, F1_Y2: 0.6379       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6873, F1_Y2: 0.6379       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6372       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6372       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6873, F1_Y2: 0.6379       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6882, F1_Y2: 0.6393       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6891, F1_Y2: 0.6408       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6365       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6873, F1_Y2: 0.6387       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6873, F1_Y2: 0.6387       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6358       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6344       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6344       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6344       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6344       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6344       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6344       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6344       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6358       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6845, F1_Y2: 0.6344       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6366       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6358       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6350       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6350       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.40681818]\n",
      " [0.29090908]]\n",
      "Group EO:\n",
      "[[0.58371043]\n",
      " [0.5119048 ]]\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6350       ***********\n",
      "================================================================================\n",
      "Group DP:\n",
      "[[0.40681818]\n",
      " [0.29090908]]\n",
      "Group EO:\n",
      "[[0.58371043]\n",
      " [0.5119048 ]]\n",
      "************ Test result: accuracy_Y2: 0.6855, F1_Y2: 0.6350       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6357       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6357       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6357       ***********\n",
      "================================================================================\n",
      "************ Test result: accuracy_Y2: 0.6864, F1_Y2: 0.6357       ***********\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epoch_pre = 150\n",
    "n_epoch_tgt = 150\n",
    "\n",
    "D1_weights = 0.01 # 需要调\n",
    "D2_weights = 0.1 # 需要调\n",
    "\n",
    "best_acc_pre = 0\n",
    "best_epoch_pre = -1\n",
    "\n",
    "while best_epoch_pre < 50: # force the pretraining to run at least 50 epochs # 可以调\n",
    "    for epoch in range(1, n_epoch_pre):\n",
    "\n",
    "        M1 = M1.train()\n",
    "        M2 = M2.train()\n",
    "        H1 = H1.train()\n",
    "        FA = FA.train()\n",
    "        D1 = D1.train()\n",
    "\n",
    "\n",
    "        M1, M2, H1, FA, D1 = FairDA_transfer_train(M1, M2, H1, FA, D1, \n",
    "                                                   src_train_loader, \n",
    "                                                   L_optim, criterion=ce)\n",
    "        M1 = M1.eval()\n",
    "        M2 = M2.eval()\n",
    "        H1 = H1.eval()\n",
    "        FA = FA.eval()\n",
    "        D1 = D1.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pre_a1_test = FA(H1(M1(test_data_src.tensors[0].to(DEVICE))))\n",
    "            a1_pred = pre_a1_test.argmax(dim=1)\n",
    "            acc_a1 = accuracy_score(A1_test, a1_pred.cpu())\n",
    "\n",
    "            if acc_a1 > best_acc_pre:\n",
    "                best_acc_pre = acc_a1\n",
    "                best_epoch_pre = epoch\n",
    "                torch.save(FA,\"saved_models/FA.pt\")\n",
    "                torch.save(H1,\"saved_models/H1.pt\")\n",
    "                torch.save(M2,\"saved_models/M2.pt\")\n",
    "\n",
    "    \n",
    "print('==================================================================')\n",
    "print('                 Pretraining on source finished                   ')\n",
    "print('                       Best epoch: {:04d}                         '.format(best_epoch_pre+1))\n",
    "print('                 Best ACC on pretraining: {:.4f}                  '.format(best_acc_pre))\n",
    "print('==================================================================')\n",
    "\n",
    "\n",
    "FA = torch.load(\"saved_models/FA.pt\")\n",
    "H1 = torch.load(\"saved_models/H1.pt\")\n",
    "M2 = torch.load(\"saved_models/M2.pt\")\n",
    "FA.eval()\n",
    "H1.eval()\n",
    "M2.eval()\n",
    "\n",
    "best_result = {}\n",
    "best_epoch = -1\n",
    "best_fair = 100\n",
    "acc_thrsh = 0.6 # 需要调，每个数据集不一样\n",
    "F1_thrsh = 0.5 # 需要调，每个数据集不一样\n",
    "\n",
    "# while best_epoch < 50:\n",
    "for epoch in range(1, n_epoch_tgt):\n",
    "\n",
    "    H2 = H2.train()\n",
    "    L2 = L2.train()\n",
    "    D2 = D2.train()\n",
    "\n",
    "    H2, L2, D2 = FairDA_debias_train(H2, L2, D2, FA, H1, M2, \n",
    "                                     tgt_train_loader, \n",
    "                                     R_optim, criterion=ce, \n",
    "                                     D2_weights = D2_weights)\n",
    "    H2 = H2.eval()\n",
    "    L2 = L2.eval()\n",
    "    D2 = D2.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pre_y2_val = L2(H2(M2(valid_data_tgt.tensors[0].to(DEVICE))))\n",
    "        y2_pre_val = pre_y2_val.argmax(dim=1).cpu()\n",
    "        acc_y2_val = accuracy_score(y_valid_tgt, y2_pre_val)\n",
    "        f1_y2_val = f1_score(y_valid_tgt, y2_pre_val)\n",
    "        _, _, dp_diff_val, eo_diff_val = fair_metric(ind_valid_tgt, y2_pre_val, y_valid_tgt)\n",
    "\n",
    "        pre_y2_test = L2(H2(M2(test_data_tgt.tensors[0].to(DEVICE))))\n",
    "        y2_pred = pre_y2_test.argmax(dim=1).cpu()\n",
    "        acc_y2 = accuracy_score(y_test_tgt, y2_pred)\n",
    "        f1_y2 = f1_score(y_test_tgt, y2_pred)\n",
    "        group_dp, group_eo, dp_diff, eo_diff = fair_metric(ind_test_tgt, y2_pred, y_test_tgt)\n",
    "\n",
    "        print('************ Test result: accuracy_Y2: {:.4f}, F1_Y2: {:.4f}       ***********'.format(acc_y2, f1_y2))\n",
    "        print('================================================================================')\n",
    "\n",
    "\n",
    "\n",
    "        if acc_y2_val > acc_thrsh and f1_y2_val > F1_thrsh:\n",
    "            if best_fair > dp_diff_val + eo_diff_val:\n",
    "                best_fair = dp_diff_val + eo_diff_val\n",
    "                best_result['Epoch'] = epoch\n",
    "                best_result['ACC'] = acc_y2\n",
    "                best_result['F1'] = f1_y2\n",
    "                best_result['DP'] = dp_diff\n",
    "                best_result['EO'] = eo_diff\n",
    "                best_result['y_true'] = y_test_tgt\n",
    "                best_result['y_pred'] = y2_pred\n",
    "                print('Group DP:')\n",
    "                print(group_dp)\n",
    "                print('Group EO:')\n",
    "                print(group_eo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ Performace on Test ============================\n",
      "************         best epoch: 144.0000                       ***********\n",
      "************         best ACC: 0.6855, best F1: 0.6350        ***********\n",
      "************         best DP: 0.0580, best EO: 0.0359        ***********\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('============================ Performace on Test ============================')\n",
    "if len(best_result) > 0:\n",
    "    \n",
    "    print('************         best epoch: {:.4f}                       ***********'.format(best_result['Epoch']))\n",
    "    print('************         best ACC: {:.4f}, best F1: {:.4f}        ***********'.format(best_result['ACC'], best_result['F1']))\n",
    "    print('************         best DP: {:.4f}, best EO: {:.4f}        ***********'.format(best_result['DP'], best_result['EO']))\n",
    "    print('================================================================================')\n",
    "\n",
    "else:\n",
    "    print('Please set smaller ACC and F1 thresholds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
